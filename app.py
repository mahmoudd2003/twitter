# ========== Auto Install snscrape if missing ==========
import subprocess, sys
try:
    import snscrape  # noqa
except ImportError:
    subprocess.run(
        [sys.executable, "-m", "pip", "install", "snscrape==0.7.0.20230622", "httpx<0.28"],
        check=False
    )
# ======================================================

import streamlit as st
import pandas as pd
from libs.utils import load_baseline, save_baseline, get_env
from libs.scoring import update_ema, spike_scores
from libs.twitter_client import search_with_snscrape, search_with_tweepy
from libs.trends import rising_queries
from libs.alerts import telegram_notify

st.set_page_config(page_title="Trend Radar â€” Twitter (Arabic)", layout="wide")
st.title("ğŸ“ˆ Trend Radar â€” Twitter (Arabic)")

st.sidebar.header("Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
lang = st.sidebar.selectbox("Ø§Ù„Ù„ØºØ©", ["ar", "en"], index=0)
window_minutes = st.sidebar.number_input("Ù†Ø§ÙØ°Ø© Ø§Ù„Ø±ØµØ¯ (Ø¯Ù‚Ø§Ø¦Ù‚)", min_value=5, max_value=120, value=int(get_env("DEFAULT_WINDOW_MINUTES", 15)))
threshold = st.sidebar.number_input("Ø¹ØªØ¨Ø© Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡ (Spike Score)", min_value=5, max_value=200, value=int(get_env("DEFAULT_SPIKE_THRESHOLD", 25)))
regions = st.sidebar.text_input("Ø§Ù„Ø¯ÙˆÙ„ (Google TrendsØŒ Ù…ÙØµÙˆÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„)", value=get_env("REGIONS", "JO,SA,AE,EG"))
use_api = st.sidebar.checkbox("Ø§Ø³ØªØ®Ø¯Ø§Ù… X API (Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† snscrape)")

seed_terms = st.sidebar.text_area("Ø§Ù„ÙƒÙ„Ù…Ø§Øª/Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø±Ø§Ø¯ Ù…Ø±Ø§Ù‚Ø¨ØªÙ‡Ø§ (Ø³Ø·Ø± Ù„ÙƒÙ„ ÙƒÙ„Ù…Ø©)", value="Ø¹Ø§Ø¬Ù„\nØ¨ÙŠØ§Ù† Ø±Ø³Ù…ÙŠ\nØ§Ù„Ø±ÙŠØ§Ø¶\nØ§Ù„Ø£Ø±Ø¯Ù†\nØ¯Ø¨ÙŠ\nØ§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©").strip().splitlines()
seed_terms = [s for s in seed_terms if s.strip()]

st.sidebar.markdown("---")
if st.sidebar.button("Ø¬Ù„Ø¨ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù…Ù† Google Trends"):
    st.session_state.setdefault("trends", {})
    out = {}
    for geo in [g.strip() for g in regions.split(",") if g.strip()]:
        out[geo] = rising_queries(seed_terms, geo=geo)
    st.session_state["trends"] = out
    st.sidebar.success("ØªÙ… Ø¬Ù„Ø¨ Ø§Ù„Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª. Ø£Ù†Ø¸Ø± Ø§Ù„ØªØ¨ÙˆÙŠØ¨ ÙÙŠ Ø§Ù„Ø£Ø³ÙÙ„.")

tab1, tab2, tab3 = st.tabs(["Ø±Ø§Ø¯Ø§Ø± (Twitter)", "Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Google Trends", "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"])

with tab1:
    st.subheader("Ø§Ù„Ø±ØµØ¯ Ø§Ù„Ø­Ø§Ù„ÙŠ")
    mode = "X API" if use_api else "snscrape"
    st.caption(f"ÙˆØ¶Ø¹ Ø§Ù„Ø¨Ø­Ø«: {mode} | Ø§Ù„Ù†Ø§ÙØ°Ø©: Ø¢Ø®Ø± {window_minutes} Ø¯Ù‚ÙŠÙ‚Ø© | Ø§Ù„Ù„ØºØ©: {lang}")
    bearer = get_env("X_BEARER_TOKEN", None)
    counts, details = {}, {}

    for term in seed_terms:
        try:
            if use_api and bearer:
                tweets = search_with_tweepy(term, bearer_token=bearer, lang=lang, minutes=window_minutes)
            else:
                tweets = search_with_snscrape(term, lang=lang, minutes=window_minutes)
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª: {e}")
            tweets = []
        counts[term] = len(tweets)
        details[term] = tweets

    baseline = load_baseline()
    baseline_updated = update_ema(baseline, counts, alpha=0.3)
    scores = spike_scores(baseline_updated, counts)
    save_baseline(baseline_updated)

    df = pd.DataFrame({
        "term": list(counts.keys()),
        "count": list(counts.values()),
        "ema": [baseline_updated.get(t, {}).get("ema", 0.0) for t in counts.keys()],
        "spike_score": [scores.get(t, 0.0) for t in counts.keys()],
    }).sort_values("spike_score", ascending=False)

    st.dataframe(df, use_container_width=True)

    bot = get_env("TELEGRAM_BOT_TOKEN", "")
    chat = get_env("TELEGRAM_CHAT_ID", "")
    high = df[df["spike_score"] >= threshold]
    if not high.empty:
        st.warning(f"ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ù…Ø­ØªÙ…Ù„Ø©: {len(high)} Ù…ØµØ·Ù„Ø­ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø¹ØªØ¨Ø©")
        if st.button("Ø¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ Telegram Ø§Ù„Ø¢Ù†"):
            msg_lines = ["<b>ğŸš¨ Trend Radar Alerts</b>"]
            for _, row in high.iterrows():
                msg_lines.append(f"â€¢ <b>{row['term']}</b> â€” score={row['spike_score']}, count={row['count']}")
            ok = telegram_notify(bot, chat, "\n".join(msg_lines))
            st.success("ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡" if ok else "ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡ (ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª)")

with tab2:
    st.subheader("Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Google Trends (Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ù†Ù…Ùˆ)")
    trends_cache = st.session_state.get("trends", {})
    if not trends_cache:
        st.info("Ø§Ø³ØªØ®Ø¯Ù… Ø²Ø± 'Ø¬Ù„Ø¨ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Google Trends' Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ.")
    else:
        for geo, mapping in trends_cache.items():
            st.markdown(f"#### {geo}")
            for seed, related in mapping.items():
                if related:
                    st.write(f"**{seed}** â†’ {', '.join(related)}")
                else:
                    st.write(f"**{seed}** â†’ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª ØµØ§Ø¹Ø¯Ø© Ø­Ø§Ù„ÙŠØ§Ù‹.")

with tab3:
    st.subheader("Ù…Ù„Ø§Ø­Ø¸Ø§Øª ÙˆØ¶Ø¨Ø· Ù…ØªÙ‚Ø¯Ù…")
    st.markdown("""
- Ù†Ø§ÙØ°Ø© Ù‚ØµÙŠØ±Ø© (5â€“15 Ø¯Ù‚ÙŠÙ‚Ø©) = Ø±ØµØ¯ Ù…Ø¨ÙƒØ± Ø£Ø¯Ù‚.
- ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø§Ø³ÙŠØ© spike Ù…Ù† libs/scoring.py.
- Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª ÙÙˆØ±ÙŠØ© Ø§Ø³ØªØ®Ø¯Ù… Telegram.
- Ù„ØªÙØ¹ÙŠÙ„ X APIØŒ Ø¶Ø¹ Ù…ÙØ§ØªÙŠØ­Ùƒ ÙÙŠ .env Ø«Ù… ÙØ¹Ù‘Ù„ Ø§Ù„Ø®ÙŠØ§Ø± Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ.
""")
